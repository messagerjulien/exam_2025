{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "# Exercices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Préliminaires**: Clone de votre repo et imports"
      ],
      "metadata": {
        "id": "hfkMtaHleKAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/messagerjulien/exam_2025.git\n",
        "! cp exam_2025/utils/utils_exercices.py .\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "xiD_cI-geJjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e672e9f3-f7bf-4332-e055-d1629103e27e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exam_2025'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 59 (delta 21), reused 20 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (59/59), 1.41 MiB | 3.75 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clef personnelle pour la partie théorique**\n",
        "\n",
        "Dans la cellule suivante, choisir un entier entre 100 et 1000 (il doit être personnel). Cet entier servira de graine au générateur de nombres aléatoire a conserver pour tous les exercices.\n",
        "\n"
      ],
      "metadata": {
        "id": "J3ga_6BNc5DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySeed = 213"
      ],
      "metadata": {
        "id": "PrCTHM4od5UZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "TRWBLVpCWC06"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "\\\n",
        "\n",
        "**Exercice 1** *Une relation linéaire*\n",
        "\n",
        "La fonction *generate_dataset* fournit deux jeux de données (entraînement et test). Pour chaque jeu de données, la clef 'inputs' donne accès à un tableau numpy (numpy array) de prédicteurs empilés horizontalement : chaque ligne $i$ contient trois prédicteurs $x_i$, $y_i$ et $z_i$. La clef 'targets' renvoie le vecteur des cibles $t_i$. \\\n",
        "\n",
        "Les cibles sont liées aux prédicteurs par le modèle:\n",
        "$$ t = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z + \\epsilon$$ où $\\epsilon \\sim \\mathcal{N}(0,\\eta)$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_exercices import generate_dataset, Dataset1\n",
        "train_set, test_set = generate_dataset(mySeed)"
      ],
      "metadata": {
        "id": "gEQmgTI8my8i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Par quelle méthode simple peut-on estimer les coefficients $\\theta_k$ ? La mettre en oeuvre avec la librairie python de votre choix."
      ],
      "metadata": {
        "id": "q5XZTrXNk12K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une méthode simple pour estimer les coefficients serait la méthode des moindres carrés. On l'implémente ci-dessous :"
      ],
      "metadata": {
        "id": "KxwKxzhmXESE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Add a constant column to the predictors for the intercept term (θ0)\n",
        "X = sm.add_constant(train_set['inputs'])\n",
        "y = train_set['targets']\n",
        "\n",
        "# Create and fit the OLS model\n",
        "model = sm.OLS(y, X)\n",
        "results = model.fit()\n",
        "\n",
        "# Print the estimated coefficients\n",
        "print(results.params)"
      ],
      "metadata": {
        "id": "HITtUqHhFMkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc326db-215d-4804-d18a-7dff3ade862f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.61785638  2.07480088  2.04334089  4.31200556]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MXGXg8tlPULY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans les cellules suivantes, on se propose d'estimer les $\\theta_k$ grâce à un réseau de neurones entraîné par SGD. Quelle architecture s'y prête ? Justifier en termes d'expressivité et de performances en généralisation puis la coder dans la cellule suivante."
      ],
      "metadata": {
        "id": "CH_Z5ZEIlQPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour entraîner un réseau de neurones avec une descente de gradients stochastique, on peut utiliser une architecture simple avec un réseau de neurones à une seule couche. En termes de performance, on évite ainsi un problème de sur-apprentissage qui expliquerait trop bien notre ensemble de coefficients. De plus, on est ici avec un problème linéaire, on peut utiliser une seule couche avec les poids associés aux neurones représentant les coefficients θ1, θ2, θ3 et le biais est représenté par θ0."
      ],
      "metadata": {
        "id": "QoileSOBZPNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# Dataset et dataloader :\n",
        "dataset = Dataset1(train_set['inputs'], train_set['targets'])\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "# A coder :\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "PPx543blnxdb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Entraîner cette architecture à la tâche de régression définie par les entrées et sorties du jeu d'entraînement (compléter la cellule ci-dessous)."
      ],
      "metadata": {
        "id": "g6BSTBitpGBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "mySimpleNet = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(mySimpleNet.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "        # Zero the gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = mySimpleNet(batch_inputs)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, batch_targets)\n",
        "\n",
        "        # Backward pass (calculate gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Wjfa2Z4RoPO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8950d841-0eb5-45fc-9bcb-180fc7bf664a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Où sont alors stockées les estimations des  $\\theta_k$ ? Les extraire du réseau *mySimpleNet* dans la cellule suivante."
      ],
      "metadata": {
        "id": "OZwKogEEp2Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les valeurs des coefficients estimées par le modèle sont stockées comme poids et biais. On peut y accéder de la manière suivante :"
      ],
      "metadata": {
        "id": "_kJqbv0IdiLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weights (θ1, θ2, θ3)\n",
        "weights = mySimpleNet.linear.weight.data\n",
        "\n",
        "# Get the bias (θ0)\n",
        "bias = mySimpleNet.linear.bias.data\n",
        "\n",
        "# Print the values\n",
        "print(\"Weights :\", weights)\n",
        "print(\"Bias :\", bias)"
      ],
      "metadata": {
        "id": "EjgWp1y1rseb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be048bd6-43ea-4369-c6ca-6fedbbe33623"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights : tensor([[0.0183, 0.0147, 0.0400]])\n",
            "Bias : tensor([12.7531])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Tester ces estimations sur le jeu de test et comparer avec celles de la question 1. Commentez."
      ],
      "metadata": {
        "id": "pEB-V-oOrJED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tensor = torch.tensor(test_set['inputs'], dtype=torch.float32)  # Convert to tensor\n",
        "predictions_nn = mySimpleNet(X_test_tensor)  # Get predictions\n",
        "\n",
        "print(\"Coefficients :\", weights, bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2STMgHTieJMm",
        "outputId": "63d76d4f-75c6-460f-8fb6-6d5d78488a95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients : tensor([[0.0183, 0.0147, 0.0400]]) tensor([12.7531])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "VvV2jIrBNtzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2** *Champ réceptif et prédiction causale*"
      ],
      "metadata": {
        "id": "CpRvXCaAtsIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau défini dans la cellule suivante est utilisé pour faire le lien entre les valeurs $(x_{t' \\leq t})$ d'une série temporelle d'entrée et la valeur présente $y_t$ d'une série temporelle cible."
      ],
      "metadata": {
        "id": "8JG9wTfK5TBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from utils_exercices import Outconv, Up_causal, Down_causal\n",
        "\n",
        "class Double_conv_causal(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2, with causal convolutions that preserve input size'''\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1):\n",
        "        super(Double_conv_causal, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class causalFCN(nn.Module):\n",
        "    def __init__(self, dilation=1):\n",
        "        super(causalFCN, self).__init__()\n",
        "        size = 64\n",
        "        n_channels = 1\n",
        "        n_classes = 1\n",
        "        self.inc = Double_conv_causal(n_channels, size)\n",
        "        self.down1 = Down_causal(size, 2*size)\n",
        "        self.down2 = Down_causal(2*size, 4*size)\n",
        "        self.down3 = Down_causal(4*size, 8*size, pooling_kernel_size=5, pooling_stride=5)\n",
        "        self.down4 = Down_causal(8*size, 4*size, pooling=False, dilation=2)\n",
        "        self.up2 = Up_causal(4*size, 2*size, kernel_size=5, stride=5)\n",
        "        self.up3 = Up_causal(2*size, size)\n",
        "        self.up4 = Up_causal(size, size)\n",
        "        self.outc = Outconv(size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up2(x5, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "\n",
        "# Exemple d'utilisation\n",
        "model = causalFCN()\n",
        "# Série temporelle d'entrée (x_t):\n",
        "input_tensor1 = torch.rand(1, 1, 10000)\n",
        "# Série temporelle en sortie f(x_t):\n",
        "output = model(input_tensor1)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "fIbU1EJT1MM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2f1602-b8cb-4a32-a94e-c2b90bcd446b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** De quel type de réseau de neurones s'agit-il ? Combien de paramètres la couche self.Down1 compte-t-elle (à faire à la main) ?\n",
        "Combien de paramètres le réseau entier compte-t-il (avec un peu de code) ?"
      ],
      "metadata": {
        "id": "-mNnsYU-7R7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nb de paramètres dans self.Down1: (calcul \"à la main\")\n",
        "#64 * 3 * 128 + 128  + 2 * 128 = 24576 + 128 + 256 = 24960\n",
        "# vecteur entrée * taille du noyau * vecteur sortie + biais + 2 * vecteur sortie pour la normalisation des batchs\n",
        "\n",
        "# Nb de paramètres au total:\n",
        "from torchsummary import summary\n",
        "summary(model, (1, 10000))"
      ],
      "metadata": {
        "id": "qlYxUf6U9vH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1ff33ae0-16c4-4873-a7c2-9337dff19381"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1            [-1, 64, 10000]             256\n",
            "       BatchNorm1d-2            [-1, 64, 10000]             128\n",
            "              ReLU-3            [-1, 64, 10000]               0\n",
            "            Conv1d-4            [-1, 64, 10000]          12,352\n",
            "       BatchNorm1d-5            [-1, 64, 10000]             128\n",
            "              ReLU-6            [-1, 64, 10000]               0\n",
            "Double_conv_causal-7            [-1, 64, 10000]               0\n",
            "         MaxPool1d-8             [-1, 64, 5000]               0\n",
            "            Conv1d-9            [-1, 128, 5000]          24,704\n",
            "      BatchNorm1d-10            [-1, 128, 5000]             256\n",
            "             ReLU-11            [-1, 128, 5000]               0\n",
            "           Conv1d-12            [-1, 128, 5000]          49,280\n",
            "      BatchNorm1d-13            [-1, 128, 5000]             256\n",
            "             ReLU-14            [-1, 128, 5000]               0\n",
            "Double_conv_causal-15            [-1, 128, 5000]               0\n",
            "      Down_causal-16            [-1, 128, 5000]               0\n",
            "        MaxPool1d-17            [-1, 128, 2500]               0\n",
            "           Conv1d-18            [-1, 256, 2500]          98,560\n",
            "      BatchNorm1d-19            [-1, 256, 2500]             512\n",
            "             ReLU-20            [-1, 256, 2500]               0\n",
            "           Conv1d-21            [-1, 256, 2500]         196,864\n",
            "      BatchNorm1d-22            [-1, 256, 2500]             512\n",
            "             ReLU-23            [-1, 256, 2500]               0\n",
            "Double_conv_causal-24            [-1, 256, 2500]               0\n",
            "      Down_causal-25            [-1, 256, 2500]               0\n",
            "        MaxPool1d-26             [-1, 256, 500]               0\n",
            "           Conv1d-27             [-1, 512, 500]         393,728\n",
            "      BatchNorm1d-28             [-1, 512, 500]           1,024\n",
            "             ReLU-29             [-1, 512, 500]               0\n",
            "           Conv1d-30             [-1, 512, 500]         786,944\n",
            "      BatchNorm1d-31             [-1, 512, 500]           1,024\n",
            "             ReLU-32             [-1, 512, 500]               0\n",
            "Double_conv_causal-33             [-1, 512, 500]               0\n",
            "      Down_causal-34             [-1, 512, 500]               0\n",
            "           Conv1d-35             [-1, 256, 500]         393,472\n",
            "      BatchNorm1d-36             [-1, 256, 500]             512\n",
            "             ReLU-37             [-1, 256, 500]               0\n",
            "           Conv1d-38             [-1, 256, 500]         196,864\n",
            "      BatchNorm1d-39             [-1, 256, 500]             512\n",
            "             ReLU-40             [-1, 256, 500]               0\n",
            "Double_conv_causal-41             [-1, 256, 500]               0\n",
            "      Down_causal-42             [-1, 256, 500]               0\n",
            "  ConvTranspose1d-43            [-1, 256, 2500]         327,936\n",
            "           Conv1d-44            [-1, 128, 2500]         196,736\n",
            "      BatchNorm1d-45            [-1, 128, 2500]             256\n",
            "             ReLU-46            [-1, 128, 2500]               0\n",
            "           Conv1d-47            [-1, 128, 2500]          49,280\n",
            "      BatchNorm1d-48            [-1, 128, 2500]             256\n",
            "             ReLU-49            [-1, 128, 2500]               0\n",
            "Double_conv_causal-50            [-1, 128, 2500]               0\n",
            "        Up_causal-51            [-1, 128, 2500]               0\n",
            "  ConvTranspose1d-52            [-1, 128, 5000]          32,896\n",
            "           Conv1d-53             [-1, 64, 5000]          49,216\n",
            "      BatchNorm1d-54             [-1, 64, 5000]             128\n",
            "             ReLU-55             [-1, 64, 5000]               0\n",
            "           Conv1d-56             [-1, 64, 5000]          12,352\n",
            "      BatchNorm1d-57             [-1, 64, 5000]             128\n",
            "             ReLU-58             [-1, 64, 5000]               0\n",
            "Double_conv_causal-59             [-1, 64, 5000]               0\n",
            "        Up_causal-60             [-1, 64, 5000]               0\n",
            "  ConvTranspose1d-61            [-1, 64, 10000]           8,256\n",
            "           Conv1d-62            [-1, 64, 10000]          24,640\n",
            "      BatchNorm1d-63            [-1, 64, 10000]             128\n",
            "             ReLU-64            [-1, 64, 10000]               0\n",
            "           Conv1d-65            [-1, 64, 10000]          12,352\n",
            "      BatchNorm1d-66            [-1, 64, 10000]             128\n",
            "             ReLU-67            [-1, 64, 10000]               0\n",
            "Double_conv_causal-68            [-1, 64, 10000]               0\n",
            "        Up_causal-69            [-1, 64, 10000]               0\n",
            "           Conv1d-70             [-1, 1, 10000]              65\n",
            "          Outconv-71             [-1, 1, 10000]               0\n",
            "================================================================\n",
            "Total params: 2,872,641\n",
            "Trainable params: 2,872,641\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.04\n",
            "Forward/backward pass size (MB): 234.53\n",
            "Params size (MB): 10.96\n",
            "Estimated Total Size (MB): 245.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La couche self.down1 compte 24960 paramètres. Le réseau compte quant à lui 2872641 paramètres."
      ],
      "metadata": {
        "id": "AdaKHxCQi58h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Par quels mécanismes la taille du vecteur d'entrée est-elle réduite ? Comment est-elle restituée dans la deuxième partie du réseau ?"
      ],
      "metadata": {
        "id": "I4D46A0-8LaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La taille du vecteur d'entrée est réduite de différentes manières :\n",
        "\n",
        "\n",
        "*   Ici on utilise des couches de convolutions avec le paramètre stride > 1, ce qui permet de réduire la dimension des tenseurs. (Applique la couche de convolution ici qu'une fois sur cinq)\n",
        "*   Avec des couches de Pooling.\n",
        "\n",
        "Dans la deuxième partie du réseau, la taille est restituée par les couches Up_causal qui rétablissent les pertes des couches de convolution précédentes.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "coAMP_uEjQm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Par quels mécanismes le champ réceptif est-il augmenté ? Préciser par un calcul la taille du champ réceptif en sortie de *self.inc*."
      ],
      "metadata": {
        "id": "SVNeFnm88yV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le champ réceptif est augmenté avec chaque couche de convolution mais aussi avec l'utilisation de couches de pooling."
      ],
      "metadata": {
        "id": "qrg5heZlmkjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La taille du champ réceptif en sortie est égal à la taille du champ en entrée auquel on rajoute :"
      ],
      "metadata": {
        "id": "kZBNMHwIoZBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "champ_r = 3 + (3-1)*2 = 7\n",
        "#noyau entrée + (taille du noyau - 1) * (coefficient de dilatation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "RFHpLK_FoSSR",
        "outputId": "4c9916c7-10b9-4c51-e47d-ddb1ceb62bea"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "cannot assign to expression (<ipython-input-24-237b23b52bb6>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-237b23b52bb6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    champ_r = 3 + (3-1)*2 = 7\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Par un bout de code, déterminer empiriquement la taille du champ réceptif associé à la composante $y_{5000}$ du vecteur de sortie. (Indice: considérer les sorties associées à deux inputs qui ne diffèrent que par une composante...)"
      ],
      "metadata": {
        "id": "TVVcBPuA9EP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = causalFCN()\n",
        "\n",
        "# Create two input tensors that differ only in one component\n",
        "input_tensor1 = torch.zeros(1, 1, 10000)  # All zeros\n",
        "input_tensor2 = input_tensor1.clone()\n",
        "input_tensor2[0, 0, 5000] = 1  # Set a single element to 1\n",
        "\n",
        "# Get the model outputs for both inputs\n",
        "output1 = model(input_tensor1)\n",
        "output2 = model(input_tensor2)\n",
        "\n",
        "# Find the indices where the outputs differ\n",
        "diff_indices = torch.nonzero(output1 != output2)\n",
        "\n",
        "# The receptive field is the range of these indices\n",
        "receptive_field_start = diff_indices[:, 2].min().item()\n",
        "receptive_field_end = diff_indices[:, 2].max().item()\n",
        "receptive_field_size = receptive_field_end - receptive_field_start + 1\n",
        "\n",
        "print(\"Receptive field start:\", receptive_field_start)\n",
        "print(\"Receptive field end:\", receptive_field_end)\n",
        "print(\"Receptive field size:\", receptive_field_size)"
      ],
      "metadata": {
        "id": "69WMWCSZAg5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9cfef1-c7b7-4adf-c4ab-fa0a4e29d666"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Receptive field start: 0\n",
            "Receptive field end: 9999\n",
            "Receptive field size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** $y_{5000}$ dépend-elle des composantes $x_{t, \\space t > 5000}$ ? Justifier de manière empirique puis préciser la partie du code de Double_conv_causal qui garantit cette propriété de \"causalité\" en justifiant.  \n",
        "\n"
      ],
      "metadata": {
        "id": "gZ37skwm-Vpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elle ne dépend pas car on utilise ici des convolutions causales (causalFCN) c'est-à-dire qui ne prennent en compte que les valeurs du présent et passé."
      ],
      "metadata": {
        "id": "SoyjKPtbvx5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "qV52tusgNn6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "Exercice 3: \"Ranknet loss\""
      ],
      "metadata": {
        "id": "bm-sRzmfqc2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un [article récent](https://https://arxiv.org/abs/2403.14144) revient sur les progrès en matière de learning to rank. En voilà un extrait :"
      ],
      "metadata": {
        "id": "Wl8wUjsSM57D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nanopiero/exam_2025/refs/heads/main/utils/png_exercice3.PNG?token=GHSAT0AAAAAAC427DACOPGNDNN6UDOLVLLAZ4BB2JQ\" alt=\"extrait d'un article\" width=\"800\">"
      ],
      "metadata": {
        "id": "SDZUXMlSDpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Qu'est-ce que les auteurs appellent \"positive samples\" et \"negative samples\" ? Donner un exemple."
      ],
      "metadata": {
        "id": "9NzV1PbMNyuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce que les auteurs appellent \"positive samples\" dans l'article sont les échantillons où l'on observe l'événement souhaité, ici il s'agit d'échantillons où une personne clique sur une annonce sur un site. \"negative samples\" à l'inverse sont des échantillons où il n'y a pas le résultat souhaité."
      ],
      "metadata": {
        "id": "Zgzk5lSQrQhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans l'expression de $\\mathcal{L}_{RankNet}$, d'où proviennent les $z_i$ ? Que représentent-ils ?  "
      ],
      "metadata": {
        "id": "yIKQ5Eo9OnPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les zi sont les échantillons que l'on a en entrée du système et qui représentent les positive et negative samples."
      ],
      "metadata": {
        "id": "Z-o289WysEWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Pourquoi cette expression conduit-elle à ce que, après apprentissage, \"the estimated\n",
        "value of positive samples is greater than that of negative samples\n",
        "for each pair of positive/negative samples\" ?"
      ],
      "metadata": {
        "id": "r74fWiyvPb7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cela est dû à l'utilisation de la fonction log"
      ],
      "metadata": {
        "id": "c6UCRWLbtaBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Dans le cadre d'une approche par deep learning, quels termes utilise-t-on pour qualifier les réseaux de neurones exploités et la modalité suivant laquelle ils sont entraînés ?"
      ],
      "metadata": {
        "id": "pk1EIi_VVi3R"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}